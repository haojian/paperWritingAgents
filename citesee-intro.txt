Science builds on the past work of others. Researchers draw from prior work to synthesize existing knowledge, identify research opportunities, and find inspirations for future research. One of the fundamental ways researchers explore and learn from the literature is by reading scientific papers. This not only provides them insights into individual prior work, but the related work sections also allows scholars to discover and draw connections to additional relevant papers via inline citations [33]. This process allows researchers to contextualize the paper they are reading within cited work, become aware of research threads that influenced the current paper, and discover other important and relevant papers to further their literature reviews [23, 33, 58]. Inline citations are a key resource for discovering papers. The behavior of following multiple levels of inline citations, sometimes referred to as chaining or footnote chasing, has been observed across many scholar groups such as sociology, computer science, and economics (summarized in [44]). More specifically, one survey study estimated that inline citations accounted for around one in five (21%) of paper discoveries during research [33].

While inline citations are useful for discovering literature, it is often difficult to prioritize which citations to pay attention to in the middle of a reading task. One challenge is that even though there is some relationship between all inline citations and the citing paper, only a subset of them will be relevant to the reader’s interests at the time of reading. This is especially challenging during literature reviews, where users need to read and skim many papers, each of which may contain dozens or hundreds of inline citations. For example, a user interested in learning about text analysis techniques reading a paper about sentiment analysis on customer reviews might be interested in inline citations to prior work in natural language processing but not e-commerce marketing.

Recently, research systems have been developed to help readers discover papers. HCI researchers have designed numerous standalone interactive paper discovery tools to support exploration of the large corpora of papers (e.g., [12, 26, 47]). NLP researchers have developed technologies that analyze inline citations in a way that could be assistive to understanding those citations, for instance classifying their level of influence on the citing paper [60] or predicting their intent (e.g., whether the citation informs the methods, background, or results) [16].

What readers do not have, but could benefit from, are tools that provide in-situ support, within a paper, for the challenging task of understanding how citations relate to their own nuanced, evolving research interests and search history. Such an understanding of citations is necessary for deciding which of many citations are worth consulting. The purpose of this paper is to design and evaluate usable in-situ aids for prioritizing inline citations.

The key insight motivating our eventual design for citation prioritization aids arose from need-finding interviews (described in Section 3): participants wished for a tool that helped them keep an eye out for prior work that is cited by multiple papers they had read in a literature review. To continue the scenario above, if a user noticed a paper cited from both a paper about aspect extraction on customer reviews and another paper about sentiment analysis on news articles, the cited paper was expected to be more relevant and salient to the reader’s interest of text analysis techniques. However, keeping track of which papers are cited by multiple papers during a literature review is impractical in current reading tools: papers use opaque identifiers for citations, like reference numbers or author-year abbreviations that differ across papers. Current reading tools do not keep track of which citations a reader has seen before (a basic affordance that sees widespread use in web browsers, which render hyperlinks in purple color when they have already been visited). Even if a reader does recognize a citation that they have seen in another, they likely will not be able to recall the context from which it was cited in other papers (e.g., which sections and the citing sentences), making it difficult to assess their importance and relevance across their corpus. These factors led participants in our preliminary interviews (described in a later section) to point a concern of “missing out” on prior work that is well-known and frequently cited by other researchers working on similar topics.

In this paper, we introduce and explore the idea of a personalized paper reading experience that augments citations in a reading tool based on their connections to the current user. We developed a Chrome-extension PDF reader for scientific papers called CiteSee. Leveraging a user’s paper library, publication record, and reading history, CiteSee visually augments scientific papers to help users keep track of citations to known papers and prioritize their exploration to citations to unknown prior work that were likely relevant to their literature review topics (Figure 4). One key motivation here is that a user’s publications and paper libraries can potentially represent their longer-term research interests, and their recent paper reading history can potentially represent their fluid and shorter-term research interests, such as during literature reviews for new projects. In addition to visually augmenting inline citations, to help users better make sense of the cited papers, CiteSee keeps track of a consistent and personalized context of how different papers connect to the user’s previous activities, for example, reminding users of the context of how they discovered different papers saved in their library or how an inline citation was described by other papers in their reading history (Figure 2). The final design of CiteSee was driven by need-finding interviews with five researcher participants with varying research experiences (described in a later section), as well as several months of internal testing, design, and evaluation by the research team. The primary design challenge we addressed was to develop in-situ indicators that were simultaneously deeply informative about the contexts where a citation has been encountered before, while also being subtle, integrating into a paper reading experience without distracting or overwhelming the reader. This paper contributes:

(1) A prototype scientific paper reading tool, CiteSee. While prior work either analyzes inline citations in a non-personalized way [16, 60] or only support personalized paper discovery independent of reading [12, 26, 47], CiteSee explores the idea of a personalized reading experience focused on helping users make sense of inline citations and prioritize which citations to further consult during reading.
(2) Mechanisms for augmenting inline citations that have connections to a user’s previous activities and providing a consistent and personalized historic context to help users discover, save, and keep track of important prior work during literature reviews.
(3) A controlled lab study (N=10) focusing on paper discovery during reading which shows our simple highlighting strategy was significantly more effective than three baselines, including one that utilizes a more sophisticated semantic embedding technique.
(4) A field deployment study (N=6) with real-world literature review tasks which offers qualitative insights of how CiteSee helped participants prioritize and keep track of explorations with results suggest a 2.7x increase in paper discovery rate via inline citations compared to previously reported numbers that were based on self-reporting [33].